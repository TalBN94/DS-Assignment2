{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GMDL-HW5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iVYN9zyB9soj",
        "-ZRQ_jE9Xd2T",
        "7jaJH2RU273J",
        "KJTcfB3loeMZ",
        "L2Ii4jXSqD8l",
        "k3L-cCOKruAJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "qlPDkSnvyUZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import copy\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "models_base_path = 'drive/MyDrive/GMDL_hw5_models/'\n",
        "plots_base_path = 'drive/MyDrive/GMDL_hw5_plots/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GV0AxhnyYuJ",
        "outputId": "00b5585f-2ade-430e-922c-171e89ab0bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computer Exercise 1 - Load data using PyTorch**"
      ],
      "metadata": {
        "id": "ThOZs_PTxkAB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpbi357vwnba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44380c84-c094-41b4-bf65-f6030fa9c0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "batch_size = 64\n",
        "\n",
        "trainsetfull = datasets.SVHN(root='./data', split='train', \n",
        "                             download=True, transform=transform)\n",
        "train_size = int(0.8 * len(trainsetfull))\n",
        "validation_size = len(trainsetfull) - train_size\n",
        "testset = datasets.SVHN(root='./data', split='test', \n",
        "                        download=True, transform=transform)\n",
        "trainset, validationset = random_split(trainsetfull, \n",
        "                                       [train_size, validation_size])\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, \n",
        "                         shuffle=True, num_workers=2)\n",
        "\n",
        "validationloader = DataLoader(validationset, batch_size=batch_size, \n",
        "                              shuffle=False, num_workers=2)\n",
        "\n",
        "testloader = DataLoader(testset, batch_size=batch_size, \n",
        "                         shuffle=False, num_workers=2)\n",
        "\n",
        "dataloaders = dict()\n",
        "dataloaders['train'] = trainloader\n",
        "dataloaders['val'] = validationloader\n",
        "dataset_sizes = dict()\n",
        "dataset_sizes['train'] = train_size\n",
        "dataset_sizes['val'] = validation_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show 5 random images from the train set"
      ],
      "metadata": {
        "id": "fHCK6x6r7_rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "figure = plt.figure(figsize=(12, 12))\n",
        "for i in range(1, 6):\n",
        "  plt.subplot(1, 5, i)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(transforms.ToPILImage()(images[i]))"
      ],
      "metadata": {
        "id": "6YHJIEoR7_DD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "85977846-2131-4d1c-bc56-3b1b02196d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x864 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computer Exercise 2**"
      ],
      "metadata": {
        "id": "iVYN9zyB9soj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fully-connected neural network class"
      ],
      "metadata": {
        "id": "Qn-jnnvR9xjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 32 * 32 * 3\n",
        "output_size = 10\n",
        "\n",
        "class FC_Net(nn.Module):\n",
        "  def __init__(self, hidden1_size=128, hidden2_size=64):\n",
        "    super(FC_Net, self).__init__()\n",
        "    self.hidden1_size = hidden1_size\n",
        "    self.hidden2_size = hidden2_size\n",
        "    self.input = nn.Linear(input_size, hidden1_size)\n",
        "    self.hidden1 = nn.Linear(hidden1_size, hidden2_size)\n",
        "    self.hidden2 = nn.Linear(hidden2_size, output_size)\n",
        "\n",
        "  # x represents our data\n",
        "  def forward(self, x):\n",
        "    x = self.input(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.hidden1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.hidden2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "armUnifJ910J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional neural network class"
      ],
      "metadata": {
        "id": "XlHVyZsKBr3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_channels = 3\n",
        "hidden_channels = [10, 20]\n",
        "cnn_fc_size = 64\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, kernel_size=3):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    # Calculate convolutions output size\n",
        "    conv1_output_size = ((32 - kernel_size + 3) // 2)\n",
        "    conv2_output_size = ((conv1_output_size - kernel_size + 3) // 2)\n",
        "    conv_output_size = conv2_output_size ** 2\n",
        "\n",
        "    self.kernel_size = kernel_size\n",
        "    self.conv1 = nn.Conv2d(input_channels, hidden_channels[0], \n",
        "                           kernel_size, 1, 1)\n",
        "    self.conv2 = nn.Conv2d(hidden_channels[0], hidden_channels[1], \n",
        "                           kernel_size, 1, 1)\n",
        "    self.fc1 = nn.Linear(conv_output_size * hidden_channels[1], cnn_fc_size)\n",
        "    self.fc2 = nn.Linear(cnn_fc_size, output_size)\n",
        "\n",
        "  # x represents our data\n",
        "  def forward(self, x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2, stride=2, padding=0)\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2, stride=2, padding=0)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "L9UFOJrJBqlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computer Exercise 3 - Training**"
      ],
      "metadata": {
        "id": "-Wrd-k3LI4Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_stats(values, num_epochs, filename, params,is_loss=True, is_fc=True, \n",
        "               is_ft=False):\n",
        "  title = f'FC network {params[0]}, {params[1]}\\n' if is_fc \\\n",
        "    else f'CNN with kernel size {params[0]}\\n' if not is_ft \\\n",
        "    else f'ResNet-18 finetuned with lr={params[0]}\\n'\n",
        "  title += 'Loss per Epoch' if is_loss else 'Accuracy per Epoch'\n",
        "  plt.plot(range(num_epochs), values['train'], label='Train')\n",
        "  plt.plot(range(num_epochs), values['val'], label='Validation')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss' if is_loss else 'Accuracy')\n",
        "  plt.savefig(f'{plots_base_path}{filename}.png')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ZCw4XqsIbPuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_model(model, criterion, optimizer, dataloaders, model_name,\n",
        "                num_epochs=30, is_fc=True, is_ft=False):\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  losses = {'train': [], 'val': []}\n",
        "  accuracy = {'train': [], 'val': []}\n",
        "  params = [model.hidden1_size, model.hidden2_size] if is_fc \\\n",
        "    else [model.kernel_size] if not is_ft else [optimizer.param_groups[0]['lr']]\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "          model.train()  # Set model to training mode\n",
        "      else:\n",
        "          model.eval()   # Set model to evaluate mode\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      for inputs, labels in dataloaders[phase]:\n",
        "        if is_fc:\n",
        "          inputs = inputs.view(inputs.shape[0], -1)\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          logits = model(inputs)    # forward pass\n",
        "          _, preds = torch.max(logits, 1)\n",
        "\n",
        "          loss = criterion(logits, labels)    # calculate loss\n",
        "\n",
        "          if phase == 'train':\n",
        "            loss.backward()   # backpropogation to compute the gradients\n",
        "            optimizer.step()  # updates the weights\n",
        "\n",
        "          # statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "    \n",
        "      epoch_loss = running_loss / dataset_sizes[phase]\n",
        "      epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f}\\n'.format(\n",
        "          phase, epoch_loss, epoch_acc))\n",
        "        \n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      losses[phase].append(epoch_loss)\n",
        "      accuracy[phase].append(epoch_acc.to('cpu'))\n",
        "  \n",
        "  model.load_state_dict(best_model_wts)\n",
        "  plot_stats(losses, num_epochs, f'Loss_{model_name}', params, is_fc=is_fc, \n",
        "             is_ft=is_ft)\n",
        "  plot_stats(accuracy, num_epochs, f\"Acc_{model_name}\", params, is_loss=False,\n",
        "             is_fc=is_fc, is_ft=is_ft)\n",
        "  return model, best_acc"
      ],
      "metadata": {
        "id": "PzX-5lGKNutK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_validation_acc = 0.0\n",
        "best_model_path = ''\n",
        "is_best_fc = True\n",
        "\n",
        "# Train FC network\n",
        "print('Train FC network with hidden layers of size 128, 64')\n",
        "print('-' * 10)\n",
        "\n",
        "fcNet = FC_Net()\n",
        "optimizer_fc = optim.Adam(fcNet.parameters(), lr=0.001)\n",
        "\n",
        "fcNet.to(device)\n",
        "\n",
        "fc_model_name = f'fc_{fcNet.hidden1_size}_{fcNet.hidden2_size}'\n",
        "fcNet, fc_best_val_acc = train_model(fcNet, nn.CrossEntropyLoss(), optimizer_fc, \n",
        "                                  dataloaders, fc_model_name)\n",
        "torch.save(fcNet.state_dict(), \n",
        "           models_base_path + f'{fc_model_name}.pth')\n",
        "\n",
        "if fc_best_val_acc > best_validation_acc:\n",
        "  best_validation_acc = fc_best_val_acc\n",
        "  is_best_fc = True\n",
        "  best_model_path = models_base_path + f'{fc_model_name}.pth'\n"
      ],
      "metadata": {
        "id": "QxCGwnvNI3p6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6421ea3b-9262-4b88-acf4-597453746f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train FC network with hidden layers of size 128, 64\n",
            "----------\n",
            "Epoch 1/30\n",
            "----------\n",
            "train Loss: 2.1613 Acc: 0.2152\n",
            "\n",
            "val Loss: 2.0451 Acc: 0.2579\n",
            "\n",
            "Epoch 2/30\n",
            "----------\n",
            "train Loss: 1.9274 Acc: 0.3164\n",
            "\n",
            "val Loss: 1.7913 Acc: 0.3713\n",
            "\n",
            "Epoch 3/30\n",
            "----------\n",
            "train Loss: 1.7386 Acc: 0.3897\n",
            "\n",
            "val Loss: 1.6930 Acc: 0.4094\n",
            "\n",
            "Epoch 4/30\n",
            "----------\n",
            "train Loss: 1.6989 Acc: 0.4054\n",
            "\n",
            "val Loss: 1.6987 Acc: 0.4032\n",
            "\n",
            "Epoch 5/30\n",
            "----------\n",
            "train Loss: 1.6703 Acc: 0.4125\n",
            "\n",
            "val Loss: 1.6768 Acc: 0.4092\n",
            "\n",
            "Epoch 6/30\n",
            "----------\n",
            "train Loss: 1.6288 Acc: 0.4252\n",
            "\n",
            "val Loss: 1.5585 Acc: 0.4587\n",
            "\n",
            "Epoch 7/30\n",
            "----------\n",
            "train Loss: 1.4829 Acc: 0.4904\n",
            "\n",
            "val Loss: 1.4547 Acc: 0.5074\n",
            "\n",
            "Epoch 8/30\n",
            "----------\n",
            "train Loss: 1.4291 Acc: 0.5128\n",
            "\n",
            "val Loss: 1.4165 Acc: 0.5277\n",
            "\n",
            "Epoch 9/30\n",
            "----------\n",
            "train Loss: 1.4131 Acc: 0.5204\n",
            "\n",
            "val Loss: 1.3949 Acc: 0.5360\n",
            "\n",
            "Epoch 10/30\n",
            "----------\n",
            "train Loss: 1.3979 Acc: 0.5264\n",
            "\n",
            "val Loss: 1.3909 Acc: 0.5382\n",
            "\n",
            "Epoch 11/30\n",
            "----------\n",
            "train Loss: 1.3852 Acc: 0.5342\n",
            "\n",
            "val Loss: 1.3954 Acc: 0.5331\n",
            "\n",
            "Epoch 12/30\n",
            "----------\n",
            "train Loss: 1.3772 Acc: 0.5387\n",
            "\n",
            "val Loss: 1.3563 Acc: 0.5566\n",
            "\n",
            "Epoch 13/30\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train CNN\n",
        "print('Train CNN with kernel size 3')\n",
        "print('-' * 10)\n",
        "\n",
        "cnn = CNN()\n",
        "optimizer_cnn = optim.Adam(cnn.parameters(), lr=0.001)\n",
        "\n",
        "cnn.to(device)\n",
        "\n",
        "cnn_model_name = f'cnn_{cnn.kernel_size}'\n",
        "cnn, cnn_best_val_acc = train_model(cnn, nn.CrossEntropyLoss(), optimizer_cnn, \n",
        "                                    dataloaders, cnn_model_name,is_fc=False)\n",
        "torch.save(cnn.state_dict(), \n",
        "           models_base_path + f'{cnn_model_name}.pth')\n",
        "\n",
        "if cnn_best_val_acc > best_validation_acc:\n",
        "  best_validation_acc = cnn_best_val_acc\n",
        "  is_best_fc = False\n",
        "  best_model_path = models_base_path + f'{cnn_model_name}.pth'"
      ],
      "metadata": {
        "id": "C2MSVZ39r_Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computer exercise 4 - Hyperparameters search**"
      ],
      "metadata": {
        "id": "AtaDPj-JiMKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing different hidden layer sizes for FC network\n",
        "\n",
        "fc_params = [[512, 256], [64, 32]]\n",
        "\n",
        "for hidden_sizes in fc_params:\n",
        "  print()\n",
        "  print(f'Train FC network with hidden layers of size \\\n",
        "    {hidden_sizes[0]}, {hidden_sizes[1]}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  fcNet = FC_Net(hidden_sizes[0], hidden_sizes[1])\n",
        "  optimizer_fc = optim.Adam(fcNet.parameters(), lr=0.001)\n",
        "  fcNet.to(device)\n",
        "  fc_model_name = f'fc_{fcNet.hidden1_size}_{fcNet.hidden2_size}'\n",
        "  fcNet, curr_best_val_acc = train_model(fcNet, nn.CrossEntropyLoss(), \n",
        "                                         optimizer_fc, dataloaders, \n",
        "                                         fc_model_name)\n",
        "  \n",
        "  torch.save(fcNet.state_dict(), \n",
        "            models_base_path + f'{fc_model_name}.pth')\n",
        "  \n",
        "  if curr_best_val_acc > best_validation_acc:\n",
        "    best_validation_acc = curr_best_val_acc\n",
        "    is_best_fc = True\n",
        "    best_model_path = models_base_path + f'{fc_model_name}.pth'\n",
        "  \n",
        "# Comparing different kernel sizes for CNN\n",
        "cnn_kernel_sizes = [10, 1]\n",
        "for kernel_size in cnn_kernel_sizes:\n",
        "  print()\n",
        "  print(f'Train CNN with kernel size {kernel_size}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  cnn = CNN(kernel_size)\n",
        "  optimizer_cnn = optim.Adam(cnn.parameters(), lr=0.001)\n",
        "  cnn.to(device)\n",
        "  cnn_model_name = f'cnn_{cnn.kernel_size}'\n",
        "  cnn, curr_best_val_acc = train_model(cnn, nn.CrossEntropyLoss(), \n",
        "                                       optimizer_cnn, dataloaders, \n",
        "                                       cnn_model_name,is_fc=False)\n",
        "  \n",
        "  torch.save(cnn.state_dict(), \n",
        "            models_base_path + f'{cnn_model_name}.pth')  \n",
        "\n",
        "  if curr_best_val_acc > best_validation_acc:\n",
        "    best_validation_acc = curr_best_val_acc\n",
        "    is_best_fc = False\n",
        "    best_model_path = models_base_path + f'{cnn_model_name}.pth'"
      ],
      "metadata": {
        "id": "K729WNHnicaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 1**"
      ],
      "metadata": {
        "id": "-ZRQ_jE9Xd2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture which performed best in our experiment was the CNN with kernel size of 3.\n",
        "\n",
        "This architecture achived train loss of 0.2322 and train accuracy of 93.14%, and validation loss of 0.498 with validation accuracy of 87.61%.\n",
        "\n",
        "In terms of overfitting and based on the validation set, we can observe a minor overfitting as starting from epoch 5 we see the losses of the train and validation start to diverge, and reach a difference of about 0.25 between the train loss and the validation loss (train loss is lower). This indicates a small overfitting."
      ],
      "metadata": {
        "id": "vx8xVVGlXi-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computer exercise 5 - Test best model**"
      ],
      "metadata": {
        "id": "7jaJH2RU273J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, is_fc=True):\n",
        "  correct_count, all_count = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in dataloader:\n",
        "      if is_fc:\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      correct_pred = torch.eq(labels, preds).cpu()\n",
        "      correct_count += correct_pred.numpy().sum()\n",
        "      all_count += len(labels)\n",
        "  \n",
        "  print(f'Number of images tested: {all_count}')\n",
        "  print(f'\\nModel test accuracy: {correct_count / all_count}')"
      ],
      "metadata": {
        "id": "68NhcLnp3CKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model parameters\n",
        "best_model = FC_Net() if is_best_fc else CNN()\n",
        "best_model.load_state_dict(torch.load(best_model_path))\n",
        "best_model.to(device)\n",
        "best_model_type = 'FC' if is_best_fc else 'CNN'\n",
        "best_model_params = f'with {best_model.hidden1_size}, {best_model.hidden2_size}'\\\n",
        " if is_best_fc else f'with kernel size {best_model.kernel_size}'\n",
        "print(f'\\nBest model is {best_model_type} {best_model_params}')\n",
        "print('Testing best model...\\n')\n",
        "evaluate_model(best_model, testloader, is_fc=is_best_fc)"
      ],
      "metadata": {
        "id": "3cJ62kyU6Wso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 2**"
      ],
      "metadata": {
        "id": "KJTcfB3loeMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can't guarantee that the model which performed best on the validation set will also be the model which performs best on the test set, as it depends on the similarity between the test and validation data sets in terms of the data set size, distribution and versatility (different kinds of examples).\n",
        "\n",
        "However, it is likely to perform similar to the way it performed on the validation set, assuming we divided our data in an appropriate way for training a model.\n",
        "\n",
        "The basic assumption we made using the validation set to choose the hyper-parameters was that the validation set is similar to the test set in terms of data distribution, thus the performence on the validation set will indicate how good our model generalizes the problem."
      ],
      "metadata": {
        "id": "Mssv4xNcog3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computer exercise 6 - Tranfer learning**"
      ],
      "metadata": {
        "id": "Tjdn8Yojf2_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tune ResNet-18:"
      ],
      "metadata": {
        "id": "iorKhZx6gAtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
        "\n",
        "print('Finetuning ResNet-18 with lr=0.001')\n",
        "print('-' * 10)\n",
        "\n",
        "model_ft, _ = train_model(model_ft, nn.CrossEntropyLoss(), \n",
        "                       optimizer_ft, dataloaders,'resnet_18_ft_lr=0.001', \n",
        "                       is_fc=False, is_ft=True)\n",
        "\n",
        "torch.save(model_ft.state_dict(), models_base_path + 'resnet18_ft.pth')\n",
        "evaluate_model(model_ft, testloader, is_fc=False)"
      ],
      "metadata": {
        "id": "Cs5fYrctf8Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 3**"
      ],
      "metadata": {
        "id": "L2Ii4jXSqD8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose to finetune the ResNet, because we figured that the problem of classifying ImageNet dataset is a bit different from the problem which we try to solve, as detecting \"types\" (classes) of different objects is different from detecting a digit from a cropped street sign image. Thus, we thought it would be a better idea to train the model again to adapt it to our problem, while initializing the weights with the pretrained ResNet as it's well trained in extracting image features already."
      ],
      "metadata": {
        "id": "wkY4KOt1qIE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 4**"
      ],
      "metadata": {
        "id": "k3L-cCOKruAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new finetuned ResNet network performs much better on the validation and test datasets.\n",
        "\n",
        "Validation accuracy:\n",
        "*   Our best model: 87.61%\n",
        "*   ResNet-18 finetuned: 92.93\n",
        "\n",
        "\n",
        "Test accuracy:\n",
        "*   Our best model: 86.17%\n",
        "*   ResNet-18 finetuned: 93.02%\n",
        "\n",
        "\n",
        "\n",
        "We believe it's due to the fact that we did 'smart initialization' of the model's weights and used a model which is already trained well on extracting image features and classifying objects. This fact, alongside the finetuning we did in the training process caused the model to perform better.\n",
        "\n",
        "One thing to note is that the training process took longer in the finetuned ResNet as the architecture of the network is more complex than the networks we've built."
      ],
      "metadata": {
        "id": "yhM8s3FKr9Ho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 5**"
      ],
      "metadata": {
        "id": "8hKKGSKOi_4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for lr in [0.1, 0.005, 0.0001]:\n",
        "  model_ft = models.resnet18(pretrained=True)\n",
        "  num_ftrs = model_ft.fc.in_features\n",
        "  model_ft.fc = nn.Linear(num_ftrs, 10)\n",
        "  model_ft = model_ft.to(device)\n",
        "  optimizer_ft = optim.Adam(model_ft.parameters(), lr=lr)\n",
        "  print()\n",
        "  print(f'Finetuning ResNet-18 with lr={lr}')\n",
        "  print('-' * 10)\n",
        "  model_ft = train_model(model_ft, nn.CrossEntropyLoss(), \n",
        "                       optimizer_ft, dataloaders, f'resnet_18_ft_lr={lr}', \n",
        "                       is_fc=False, is_ft=True)"
      ],
      "metadata": {
        "id": "9ho_UGYii76T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We experimented with 3 other learning rates as can be seen above. The results were:\n",
        "\n",
        "\n",
        "*   For a large learning rate (`lr=1`), we see that the optimization process diverged and we got poor results. We assume this is due to the fact that the learning rate was too large.\n",
        "*   For a similar learning rate (although 5 times larger, `lr=0.005`), we observed similar results to the original learning rate (`lr=0.001`), so it seems like multiplying the learning rate didn't have much effect.\n",
        "*   For a small learning rate (`lr=0.0001`), we see a little bit less overfitting, but not so much that makes a difference in the results, as we still got about 92% validation accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VWBpLRHb_Dan"
      }
    }
  ]
}